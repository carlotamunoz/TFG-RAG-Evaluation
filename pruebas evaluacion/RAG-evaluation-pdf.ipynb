{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa0b81dc-7688-468f-b1ed-5f0b52b36c39",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n",
      "C:\\Users\\carlo\\anaconda3\\envs\\rag\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#%pip install langchain\n",
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_ollama import OllamaEmbeddings, ChatOllama\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders.parsers import RapidOCRBlobParser\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_ollama import OllamaEmbeddings\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.embeddings import LangchainEmbeddingsWrapper\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import LLMContextPrecisionWithoutReference\n",
    "from ragas import SingleTurnSample\n",
    "from ragas.metrics import BleuScore\n",
    "from ragas.metrics import AspectCritic\n",
    "from datasets import Dataset\n",
    "from ragas import evaluate\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09466b9-008e-4374-9a44-bdb62857bf91",
   "metadata": {},
   "source": [
    "# CREACION DE RAG PARA PDF"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f418e4c4-e139-4afa-88a7-7d1eb8271397",
   "metadata": {},
   "source": [
    "https://docs.ragas.io/en/stable/getstarted/rag_eval/#analyze-results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c27ffba4-8211-428c-bece-e1bcf009a2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAG:\n",
    "    RAG_TEMPLATE = \"\"\"\n",
    "You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
    "\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "Answer the following question:\n",
    "\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "    def __init__(self, model=\"llama3\", base_url=\"https://ollama.gsi.upm.es/\"):\n",
    "        # Inicializa el modelo de lenguaje y las embeddings\n",
    "        self.model = ChatOllama(model=model, base_url=base_url)\n",
    "        self.embeddings = OllamaEmbeddings(model=\"nomic-embed-text\")\n",
    "        self.vectorstore = None\n",
    "        self.docs = None\n",
    "        self.prompt_template = ChatPromptTemplate.from_template(self.RAG_TEMPLATE)\n",
    "\n",
    "    def load_documents(self, file_path, mode=\"page\", images_inner_format=\"markdown-img\"):\n",
    "        \"\"\"\n",
    "        Carga documentos desde un archivo PDF, los divide en fragmentos (chunks) \n",
    "        y crea un vectorstore basado en las embeddings.\n",
    "        \"\"\"\n",
    "        # Carga del PDF utilizando PyPDFLoader\n",
    "        loader = PyPDFLoader(file_path, mode=mode, images_inner_format=images_inner_format)\n",
    "        self.docs = loader.load()\n",
    "        # Divide el contenido en chunks de 500 caracteres sin solapamiento\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "        all_splits = text_splitter.split_documents(self.docs)\n",
    "        # Crea el vectorstore a partir de los fragmentos y las embeddings\n",
    "        self.vectorstore = Chroma.from_documents(documents=all_splits, embedding=self.embeddings)\n",
    "\n",
    "    def get_most_relevant_docs(self, query):\n",
    "        \"\"\"\n",
    "        Recupera los documentos más relevantes para la consulta utilizando el vectorstore.\n",
    "        \"\"\"\n",
    "        if not self.vectorstore:\n",
    "            raise ValueError(\"No se han cargado documentos. Ejecuta load_documents primero.\")\n",
    "        retriever = self.vectorstore.as_retriever()\n",
    "        return retriever.get_relevant_documents(query)\n",
    "\n",
    "    def generate_answer(self, query, relevant_docs):\n",
    "        \"\"\"\n",
    "        Genera una respuesta para la consulta, usando los documentos relevantes.\n",
    "        \"\"\"\n",
    "        # Une el contenido de los documentos en un bloque de texto\n",
    "        context = \"\\n\\n\".join(doc.page_content for doc in relevant_docs)\n",
    "        # Rellena la plantilla del prompt con el contexto y la pregunta\n",
    "        prompt = self.prompt_template.format(context=context, question=query)\n",
    "        messages = [\n",
    "            (\"system\", \"You are an assistant that answers questions based solely on the provided context.\"),\n",
    "            (\"human\", prompt)\n",
    "        ]\n",
    "        ai_msg = self.model.invoke(messages)\n",
    "        return ai_msg.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f2d504-6cf3-4dc9-8834-6a1e75b06292",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = RAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0fd7b4f-d644-43a8-b02a-bef9b9a0b694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load documents\n",
    "rag.load_documents(file_path = \"./jc3prueba.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d776f74-19f4-4e9a-8ca2-88644b53b479",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions =[\"¿Cuál es el propósito principal del JC3IEDM?\",\n",
    "            \"¿Cuáles son las dos categorías principales de 'objeto' que abarca el diseño del modelo?\",\n",
    "            \"¿Qué papel juega la entidad 'REPORTING-DATA' en el JC3IEDM?\"]\n",
    "ground_truth = [\"El JC3IEDM tiene como propósito principal definir la información que se va a intercambiar entre sistemas de mando y control automatizados (C2IS) para lograr la interoperabilidad. También puede servir como base coherente para otros mecanismos de intercambio de información.\",\n",
    "                \"El diseño del modelo abarca dos categorías de objetos: aquellos que pueden ser identificados individualmente (OBJECT-ITEM) y aquellos que representan propiedades agrupadas o de clase (OBJECT-TYPE). La vinculación de un ítem a un tipo es obligatoria en el modelo\",\n",
    "                \"'REPORTING-DATA' especifica la fuente, calidad y momento de los datos reportados. Permite comparar diferentes informes y mantener un registro histórico de la información\"\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a08c337a-af21-427a-899e-fa2aff1bbd85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Temp\\ipykernel_21892\\2860725801.py:43: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  return retriever.get_relevant_documents(query)\n"
     ]
    }
   ],
   "source": [
    "dataset = []\n",
    "\n",
    "for query,reference in zip(questions,ground_truth):\n",
    "\n",
    "    relevant_docs = rag.get_most_relevant_docs(query)\n",
    "    response = rag.generate_answer(query, relevant_docs)\n",
    "    dataset.append(\n",
    "        {\n",
    "            \"user_input\":query,\n",
    "            \"retrieved_contexts\":relevant_docs,\n",
    "            \"response\":response,\n",
    "            \"reference\":reference\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "afc2a5e0-ff0c-4018-a7d1-1548e36665de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'user_input': '¿Cuál es el propósito principal del JC3IEDM?',\n",
       "  'retrieved_contexts': [Document(id='921c4df6-241b-4d6d-b45c-69f2fb4781ec', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 3, 'page_label': '4', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='Figure 37.  High-Level View of JC3IEDM ................................................................................... 68'),\n",
       "   Document(id='ee5f5d93-8acb-4c4f-aaf7-466e90d873b3', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 3, 'page_label': '4', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='Figure 37.  High-Level View of JC3IEDM ................................................................................... 68'),\n",
       "   Document(id='66d4bfdd-bd3d-40f4-a8b9-bb1070ad384e', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 72, 'page_label': '73', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='JC3IEDM OVERVIEW – UK – DMWG \\n16 February 2007 \\nEdition 3.1a \\n61 \\nhas-a-role-with-respect-to\\nhas-relevant-information-in\\nhas-relevant-information-in\\nhas-relevant-information-in\\nhas-relevant-information-in\\nis-the-subject-of\\nis-the-object-of\\nis-administered-by\\napplies-to\\napplies-to\\napplies-to\\napplies-to\\nprovides-information-related-to /\\nis-amplif ied-by\\nis-the-reporting-agent-for /\\nis-reported-by\\nREFERENCE\\nREPORTING-DATA\\nCAPABILITY\\nOBJECT-ITEM\\nOBJECT-TYPE\\nORGANISATION\\nACTION'),\n",
       "   Document(id='01ffc30e-66b6-4866-8a0f-7f04345dc916', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 72, 'page_label': '73', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='JC3IEDM OVERVIEW – UK – DMWG \\n16 February 2007 \\nEdition 3.1a \\n61 \\nhas-a-role-with-respect-to\\nhas-relevant-information-in\\nhas-relevant-information-in\\nhas-relevant-information-in\\nhas-relevant-information-in\\nis-the-subject-of\\nis-the-object-of\\nis-administered-by\\napplies-to\\napplies-to\\napplies-to\\napplies-to\\nprovides-information-related-to /\\nis-amplif ied-by\\nis-the-reporting-agent-for /\\nis-reported-by\\nREFERENCE\\nREPORTING-DATA\\nCAPABILITY\\nOBJECT-ITEM\\nOBJECT-TYPE\\nORGANISATION\\nACTION')],\n",
       "  'response': 'Based on the provided context, it appears that the main purpose of JC3IEDM is not explicitly stated. However, it seems to be related to reporting and providing information, as indicated by the keywords \"REPORTING-DATA\", \"OBJECT-ITEM\", and \"ORGANISATION\".',\n",
       "  'reference': 'El JC3IEDM tiene como propósito principal definir la información que se va a intercambiar entre sistemas de mando y control automatizados (C2IS) para lograr la interoperabilidad. También puede servir como base coherente para otros mecanismos de intercambio de información.'},\n",
       " {'user_input': \"¿Cuáles son las dos categorías principales de 'objeto' que abarca el diseño del modelo?\",\n",
       "  'retrieved_contexts': [Document(id='72dfa882-4924-4791-884d-83a6ed133876', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 31, 'page_label': '32', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='3.2.1.2 The model in its most abstract sense may be thought of as a metamodel that \\nprovides the structural skeleton for following broad topics: \\na. Objects of interest and their inherent properties \\nb. Past, present, or future situation as represented by facts about the objects \\nc. Past, present, or future activities that involve the objects \\nd. Mechanisms for grouping data into information packages. \\n \\nThe content of the model in terms of attributes  and sets of enumerated values represents'),\n",
       "   Document(id='5b8fc3ff-03a9-4f56-ba48-73be0fb21002', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 31, 'page_label': '32', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='3.2.1.2 The model in its most abstract sense may be thought of as a metamodel that \\nprovides the structural skeleton for following broad topics: \\na. Objects of interest and their inherent properties \\nb. Past, present, or future situation as represented by facts about the objects \\nc. Past, present, or future activities that involve the objects \\nd. Mechanisms for grouping data into information packages. \\n \\nThe content of the model in terms of attributes  and sets of enumerated values represents'),\n",
       "   Document(id='e9d037e8-11bb-4c9a-aa59-2396be93ba41', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 32, 'page_label': '33', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='data that are to be recorded for each concept of  interest. This edition of the model contains \\n241 entities. The entire structure is generated from 15 independent entities, that is, entities'),\n",
       "   Document(id='e3673cc2-ac01-4a01-bb5c-4325737c3368', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 32, 'page_label': '33', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='data that are to be recorded for each concept of  interest. This edition of the model contains \\n241 entities. The entire structure is generated from 15 independent entities, that is, entities')],\n",
       "  'response': 'According to the provided context, the two main categories of \"objects\" that the model design encompasses are:\\n\\n* a. Objects of interest and their inherent properties\\n* c. Past, present, or future activities that involve the objects',\n",
       "  'reference': 'El diseño del modelo abarca dos categorías de objetos: aquellos que pueden ser identificados individualmente (OBJECT-ITEM) y aquellos que representan propiedades agrupadas o de clase (OBJECT-TYPE). La vinculación de un ítem a un tipo es obligatoria en el modelo'},\n",
       " {'user_input': \"¿Qué papel juega la entidad 'REPORTING-DATA' en el JC3IEDM?\",\n",
       "  'retrieved_contexts': [Document(id='7966fd92-8cc4-41fd-a81b-e1df14e4e6b2', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 80, 'page_label': '81', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='JC3IEDM OVERVIEW – UK – DMWG \\n16 February 2007 \\nEdition 3.1a \\n69 \\n \\n3.22.3 REPORTING-DATA plays a special role in the model. It records reporting \\ndata about much of the information held in the lower part of the model. It also serves as \\nthe means for that information to be used in multiple ways in developing courses of action, \\nallocating resources, preparing plans, and execu ting operations orders, all of which are in \\nthe province of the upper part of the model.'),\n",
       "   Document(id='b40bc433-e8d6-4b1d-8bca-69048c36e61e', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 80, 'page_label': '81', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='JC3IEDM OVERVIEW – UK – DMWG \\n16 February 2007 \\nEdition 3.1a \\n69 \\n \\n3.22.3 REPORTING-DATA plays a special role in the model. It records reporting \\ndata about much of the information held in the lower part of the model. It also serves as \\nthe means for that information to be used in multiple ways in developing courses of action, \\nallocating resources, preparing plans, and execu ting operations orders, all of which are in \\nthe province of the upper part of the model.'),\n",
       "   Document(id='20981d50-9755-42aa-ba05-4bc15d067f75', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 69, 'page_label': '70', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='3.16.2.1 REPORTING-DATA is defined as th e specification of source, quality \\nand timing that applies to reported da ta. Its structure is illustrated in Figure 29. It has a \\nmandatory relationship to ORGANI SATION whose role is that of a reporting agent. Its \\ntwo subtypes serve to specify timing information. \\n3.16.2.2 Ability to cite sources of informa tion that are external to the data \\nstructures is useful. The sources could be ADa tP-3 messages, printouts of electronic mail,'),\n",
       "   Document(id='83ce2893-3d80-441b-8a4d-7968618f0bfd', metadata={'author': 'MIP DMWG', 'creationdate': '2007-02-13T11:46:49+01:00', 'creator': 'Acrobat PDFMaker 7.0.7 for Word', 'moddate': '2024-12-11T11:35:47+01:00', 'page': 69, 'page_label': '70', 'producer': 'Acrobat Distiller 7.0.5 (Windows)', 'source': './jc3prueba.pdf', 'subject': 'Overview of JC3IEDM Specification', 'title': 'JC3IEDM', 'total_pages': 82}, page_content='3.16.2.1 REPORTING-DATA is defined as th e specification of source, quality \\nand timing that applies to reported da ta. Its structure is illustrated in Figure 29. It has a \\nmandatory relationship to ORGANI SATION whose role is that of a reporting agent. Its \\ntwo subtypes serve to specify timing information. \\n3.16.2.2 Ability to cite sources of informa tion that are external to the data \\nstructures is useful. The sources could be ADa tP-3 messages, printouts of electronic mail,')],\n",
       "  'response': \"La entidad 'REPORTING-DATA' juega un papel especial en el JC3IEDM ya que registra datos de reporte sobre información almacenada en la parte baja del modelo y se utiliza para desarrollar cursos de acción, asignar recursos, preparar planes y ejecutar órdenes de operaciones en la parte alta del modelo. Además, especifica fuentes, calidad y timing de los datos informados.\",\n",
       "  'reference': \"'REPORTING-DATA' especifica la fuente, calidad y momento de los datos reportados. Permite comparar diferentes informes y mantener un registro histórico de la información\"}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b3e3969-10a5-493c-80c5-27ba02d76724",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas import EvaluationDataset\n",
    "\n",
    "# Convierte los documentos a strings usando el atributo page_content\n",
    "for sample in dataset:\n",
    "    sample['retrieved_contexts'] = [doc.page_content for doc in sample['retrieved_contexts']]\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "146ef5a7-d8a0-40b3-83d7-bfb7ab2177c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████| 9/9 [00:51<00:00,  5.68s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'context_recall': 0.8889, 'faithfulness': 1.0000, 'factual_correctness(mode=f1)': 0.3767}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOllama(model=\"llama3\", base_url= \"https://ollama.gsi.upm.es/\" ))\n",
    "evaluator_embeddings = LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\"nomic-embed-text\"))\n",
    "\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "result = evaluate(dataset=evaluation_dataset,metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],llm=evaluator_llm)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8aa81d5a-85dc-4b0a-aca7-89db57f66162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"RAGAS_APP_TOKEN\"] = \"apt.4054-53fd2731274f-4395-87c1-2cd16721-ebca3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4dbfef31-d10b-4f01-a87f-bd98c12e6a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results uploaded! View at https://app.ragas.io/dashboard/alignment/evaluation/fa02a105-833d-48e6-a00a-b8bbbcd9c755\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/evaluation/fa02a105-833d-48e6-a00a-b8bbbcd9c755'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfa7ca5-0051-44fa-bfc4-9ac314a41a12",
   "metadata": {},
   "source": [
    "# GENERACION DE UN TESTSET "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20103800-bd32-4704-910d-ca0293bf736c",
   "metadata": {},
   "source": [
    "https://docs.ragas.io/en/stable/getstarted/rag_testset_generation/#generate-testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "547910b8-a710-492a-97b3-c69f2af633f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_llm = LangchainLLMWrapper(ChatOllama(model=\"llama3\", base_url=\"https://ollama.gsi.upm.es/\"))\n",
    "generator_embeddings = LangchainEmbeddingsWrapper(OllamaEmbeddings(model=\"nomic-embed-text\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61693a48-fc42-4297-acd3-79a4a0dc22c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ragas.testset.graph import KnowledgeGraph\n",
    "\n",
    "kg = KnowledgeGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "50382a17-d786-4c5a-88be-be4faf724756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnowledgeGraph inicial: KnowledgeGraph(nodes: 0, relationships: 0)\n",
      "KnowledgeGraph tras agregar documentos: KnowledgeGraph(nodes: 82, relationships: 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "unable to apply transformation: 'headlines' property not found in this node                     | 0/82 [00:00<?, ?it/s]\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "unable to apply transformation: 'headlines' property not found in this node\n",
      "Property 'summary' already exists in node '1ddd27'. Skipping!                         | 56/110 [01:16<01:05,  1.21s/it]\n",
      "Property 'summary' already exists in node '4d35c5'. Skipping!                         | 57/110 [01:18<01:19,  1.51s/it]\n",
      "Property 'summary' already exists in node 'e1a472'. Skipping!                         | 58/110 [01:20<01:14,  1.43s/it]\n",
      "Property 'summary' already exists in node '7e7967'. Skipping!                         | 59/110 [01:21<01:18,  1.55s/it]\n",
      "Property 'summary' already exists in node '606b50'. Skipping!\n",
      "Property 'summary' already exists in node '3f2dda'. Skipping!▉                        | 61/110 [01:24<01:14,  1.53s/it]\n",
      "Property 'summary' already exists in node 'ee4d34'. Skipping!█▍                       | 62/110 [01:25<01:03,  1.32s/it]\n",
      "Property 'summary' already exists in node 'e36704'. Skipping!█▉                       | 63/110 [01:26<00:55,  1.17s/it]\n",
      "Property 'summary' already exists in node 'c42973'. Skipping!██▍                      | 64/110 [01:27<00:59,  1.29s/it]\n",
      "Property 'summary' already exists in node '846f2d'. Skipping!██▉                      | 65/110 [01:29<01:03,  1.40s/it]\n",
      "Property 'summary' already exists in node 'b453ac'. Skipping!███▍                     | 66/110 [01:30<00:59,  1.35s/it]\n",
      "Property 'summary' already exists in node '14ad73'. Skipping!███▉                     | 67/110 [01:32<01:03,  1.48s/it]\n",
      "Property 'summary' already exists in node '274c54'. Skipping!████▍                    | 68/110 [01:33<00:59,  1.42s/it]\n",
      "Property 'summary' already exists in node '653678'. Skipping!████▊                    | 69/110 [01:36<01:06,  1.63s/it]\n",
      "Property 'summary' already exists in node 'b0077a'. Skipping!█████▎                   | 70/110 [01:37<00:58,  1.46s/it]\n",
      "Property 'summary' already exists in node '6806d0'. Skipping!█████▊                   | 71/110 [01:38<00:53,  1.36s/it]\n",
      "Property 'summary' already exists in node '34ff8f'. Skipping!██████▎                  | 72/110 [01:39<00:49,  1.30s/it]\n",
      "Property 'summary' already exists in node 'e31cd2'. Skipping!██████▊                  | 73/110 [01:42<01:02,  1.69s/it]\n",
      "Property 'summary' already exists in node '8239fe'. Skipping!███████▎                 | 74/110 [01:43<00:53,  1.49s/it]\n",
      "Property 'summary' already exists in node '3518a3'. Skipping!███████▊                 | 75/110 [01:43<00:44,  1.27s/it]\n",
      "Property 'summary' already exists in node '7117d4'. Skipping!████████▎                | 76/110 [01:46<00:59,  1.74s/it]\n",
      "Property 'summary' already exists in node '47508e'. Skipping!████████▊                | 77/110 [01:47<00:51,  1.55s/it]\n",
      "Property 'summary' already exists in node 'd5d861'. Skipping!█████████▎               | 78/110 [01:49<00:51,  1.61s/it]\n",
      "Property 'summary' already exists in node 'e41c9f'. Skipping!█████████▊               | 79/110 [01:50<00:43,  1.40s/it]\n",
      "Property 'summary' already exists in node 'a6dfcf'. Skipping!██████████▎              | 80/110 [01:52<00:46,  1.55s/it]\n",
      "Property 'summary' already exists in node 'a3b935'. Skipping!██████████▊              | 81/110 [01:53<00:38,  1.34s/it]\n",
      "Property 'summary' already exists in node '74752f'. Skipping!███████████▎             | 82/110 [01:54<00:35,  1.27s/it]\n",
      "Property 'summary' already exists in node '7e3927'. Skipping!███████████▋             | 83/110 [01:55<00:32,  1.19s/it]\n",
      "Property 'summary' already exists in node '74a293'. Skipping!████████████▏            | 84/110 [01:57<00:39,  1.50s/it]\n",
      "Property 'summary' already exists in node 'b7b98e'. Skipping!████████████▋            | 85/110 [01:58<00:35,  1.42s/it]\n",
      "Property 'summary' already exists in node '81c9cb'. Skipping!█████████████▏           | 86/110 [01:59<00:29,  1.22s/it]\n",
      "Property 'summary' already exists in node '7ce5fc'. Skipping!█████████████▋           | 87/110 [02:01<00:36,  1.58s/it]\n",
      "Property 'summary' already exists in node '8bc5e8'. Skipping!██████████████▏          | 88/110 [02:03<00:32,  1.49s/it]\n",
      "Property 'summary' already exists in node '4f9b08'. Skipping!██████████████▋          | 89/110 [02:03<00:26,  1.28s/it]\n",
      "Property 'summary' already exists in node 'f471a8'. Skipping!███████████████▏         | 90/110 [02:05<00:27,  1.37s/it]\n",
      "Property 'summary' already exists in node '174447'. Skipping!███████████████▋         | 91/110 [02:07<00:27,  1.43s/it]\n",
      "Property 'summary' already exists in node '539746'. Skipping!████████████████▏        | 92/110 [02:08<00:23,  1.32s/it]\n",
      "Property 'summary' already exists in node '1e856b'. Skipping!████████████████▋        | 93/110 [02:09<00:20,  1.18s/it]\n",
      "Property 'summary' already exists in node 'e482e8'. Skipping!█████████████████▏       | 94/110 [02:10<00:18,  1.16s/it]\n",
      "Property 'summary' already exists in node '78f094'. Skipping!█████████████████▋       | 95/110 [02:12<00:20,  1.37s/it]\n",
      "Property 'summary' already exists in node '0ff946'. Skipping!██████████████████▏      | 96/110 [02:12<00:16,  1.19s/it]\n",
      "Property 'summary' already exists in node 'd8213e'. Skipping!██████████████████▌      | 97/110 [02:14<00:16,  1.26s/it]\n",
      "Property 'summary' already exists in node '879414'. Skipping!███████████████████      | 98/110 [02:15<00:14,  1.18s/it]\n",
      "Property 'summary' already exists in node '29bef5'. Skipping!███████████████████▌     | 99/110 [02:16<00:13,  1.26s/it]\n",
      "Property 'summary' already exists in node 'a07e28'. Skipping!\n",
      "Property 'summary' already exists in node '67a29c'. Skipping!███████████████████▋    | 101/110 [02:18<00:10,  1.20s/it]\n",
      "Property 'summary' already exists in node '64b801'. Skipping!████████████████████▏   | 102/110 [02:19<00:08,  1.06s/it]\n",
      "Property 'summary' already exists in node '1cd2b1'. Skipping!████████████████████▋   | 103/110 [02:21<00:08,  1.26s/it]\n",
      "Property 'summary' already exists in node 'd2f323'. Skipping!█████████████████████   | 104/110 [02:22<00:06,  1.09s/it]\n",
      "Property 'summary' already exists in node 'ccce04'. Skipping!█████████████████████▌  | 105/110 [02:23<00:06,  1.21s/it]\n",
      "Property 'summary' already exists in node '4451e6'. Skipping!██████████████████████  | 106/110 [02:24<00:04,  1.17s/it]\n",
      "Property 'summary' already exists in node 'fdd987'. Skipping!██████████████████████▌ | 107/110 [02:26<00:03,  1.24s/it]\n",
      "Property 'summary' already exists in node 'ce1fcf'. Skipping!\n",
      "Property 'summary' already exists in node '94edee'. Skipping!███████████████████████▌| 109/110 [02:27<00:00,  1.05it/s]\n",
      "Property 'summary_embedding' already exists in node '7e7967'. Skipping!                        | 0/116 [00:00<?, ?it/s]\n",
      "Property 'summary_embedding' already exists in node '1ddd27'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4d35c5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e1a472'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '606b50'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ee4d34'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3f2dda'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e36704'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'c42973'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '846f2d'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b453ac'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '14ad73'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '653678'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '274c54'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '6806d0'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b0077a'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '34ff8f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e31cd2'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8239fe'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd5d861'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '3518a3'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7117d4'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '47508e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a6dfcf'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e41c9f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a3b935'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '74752f'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7e3927'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '81c9cb'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '74a293'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'b7b98e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4f9b08'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '7ce5fc'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '8bc5e8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '174447'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '539746'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'f471a8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1e856b'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'e482e8'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '78f094'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '0ff946'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '29bef5'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd8213e'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '879414'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'a07e28'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '67a29c'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '1cd2b1'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '64b801'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'd2f323'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ccce04'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'fdd987'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '4451e6'. Skipping!\n",
      "Property 'summary_embedding' already exists in node '94edee'. Skipping!\n",
      "Property 'summary_embedding' already exists in node 'ce1fcf'. Skipping!\n",
      "                                                                                                                       "
     ]
    }
   ],
   "source": [
    "# 1. Cargar documentos usando la clase RAG\n",
    "rag = RAG()\n",
    "rag.load_documents(file_path=\"./jc3prueba.pdf\")\n",
    "docs = rag.docs  # Lista de documentos cargados\n",
    "\n",
    "# 2. Crear un KnowledgeGraph vacío e incorporar los documentos como nodos\n",
    "from ragas.testset.graph import KnowledgeGraph, Node, NodeType\n",
    "\n",
    "kg = KnowledgeGraph()\n",
    "print(\"KnowledgeGraph inicial:\", kg)  # Debería mostrar: KnowledgeGraph(nodes: 0, relationships: 0)\n",
    "\n",
    "for doc in docs:\n",
    "    kg.nodes.append(\n",
    "        Node(\n",
    "            type=NodeType.DOCUMENT,\n",
    "            properties={\n",
    "                \"page_content\": doc.page_content,\n",
    "                \"document_metadata\": doc.metadata\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "print(\"KnowledgeGraph tras agregar documentos:\", kg)  # Ahora debería mostrar varios nodos (por ejemplo, 10)\n",
    "\n",
    "# 3. Definir un prompt personalizado para extraer headlines\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "headlines_extractor_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "You are a headlines extractor for document nodes. Extract a concise headline from the given page_content.\n",
    "Return your answer as a JSON object with the key \"headlines\". \n",
    "For example, if the content is:\n",
    "\"Joint Consultation Command & Control Information Exchange Data Model (JC3IEDM) facilitates interoperability...\"\n",
    "Then your output should be:\n",
    "{\"headlines\": \"Interoperability in JC3IEDM\"}\n",
    "If no clear headline is found, return {\"headlines\": \"\"}.\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "# 4. Obtener y aplicar las transformaciones al KnowledgeGraph\n",
    "from ragas.testset.transforms import default_transforms, apply_transforms\n",
    "\n",
    "# Usamos el mismo LLM y modelo de embeddings que para la generación del testset\n",
    "transformer_llm = generator_llm\n",
    "embedding_model = generator_embeddings\n",
    "\n",
    "# Obtener las transformaciones por defecto\n",
    "trans = default_transforms(documents=docs, llm=transformer_llm, embedding_model=embedding_model)\n",
    "\n",
    "# Inyectar el prompt personalizado para la transformación de headlines (si existe)\n",
    "for transform in trans:\n",
    "    if hasattr(transform, \"name\") and transform.name == \"headlines_extractor\":\n",
    "        transform.prompt = headlines_extractor_prompt\n",
    "\n",
    "apply_transforms(kg, trans)\n",
    "\n",
    "# 5. Guardar y recargar el KnowledgeGraph (opcional pero útil para verificar el enriquecimiento)\n",
    "kg.save(\"knowledge_graph.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d5343d6-7791-48d8-956e-994f66f5703e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KnowledgeGraph cargado: KnowledgeGraph(nodes: 139, relationships: 3726)\n",
      "Distribución original de queries: [(SingleHopSpecificQuerySynthesizer(name='single_hop_specifc_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOllama(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
      "1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
      "2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
      ", examples=[(QueryCondition(persona=Persona(name='Software Engineer', role_description='Focuses on coding best practices and system design.'), term='microservices', query_style='Formal', query_length='Medium', context='Microservices are an architectural style where applications are structured as a collection of loosely coupled services. Each service is fine-grained and focuses on a single functionality.'), GeneratedQueryAnswer(query='What is the purpose of microservices in software architecture?', answer='Microservices are designed to structure applications as a collection of loosely coupled services, each focusing on a single functionality.'))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english), property_name='entities'), 0.3333333333333333), (MultiHopAbstractQuerySynthesizer(name='multi_hop_abstract_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOllama(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
      "1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
      "2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
      "3. **Multi-Hop Context Tags**:\n",
      "   - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
      "   - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), concept_combination_prompt=ConceptCombinationPrompt(instruction=Form combinations by pairing concepts from at least two different lists.\n",
      "**Instructions:**\n",
      "- Review the concepts from each node.\n",
      "- Identify concepts that can logically be connected or contrasted.\n",
      "- Form combinations that involve concepts from different nodes.\n",
      "- Each combination should include at least one concept from two or more nodes.\n",
      "- List the combinations clearly and concisely.\n",
      "- Do not repeat the same combination more than once., examples=[(ConceptsList(lists_of_concepts=[['Artificial intelligence', 'Automation'], ['Healthcare', 'Data privacy']], max_combinations=2), ConceptCombinations(combinations=[['Artificial intelligence', 'Healthcare'], ['Automation', 'Data privacy']]))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)), 0.3333333333333333), (MultiHopSpecificQuerySynthesizer(name='multi_hop_specific_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOllama(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
      "1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
      "2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
      "3. **Multi-Hop Context Tags**:\n",
      "   - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
      "   - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), relation_type='entities_overlap', property_name='entities', theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)), 0.3333333333333333)]\n",
      "Distribución filtrada de queries: [(SingleHopSpecificQuerySynthesizer(name='single_hop_specifc_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOllama(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a single-hop query and answer based on the specified conditions (persona, term, style, length) and the provided context. Ensure the answer is entirely faithful to the context, using only the information directly from the provided context.### Instructions:\n",
      "1. **Generate a Query**: Based on the context, persona, term, style, and length, create a question that aligns with the persona's perspective and incorporates the term.\n",
      "2. **Generate an Answer**: Using only the content from the provided context, construct a detailed answer to the query. Do not add any information not included in or inferable from the context.\n",
      ", examples=[(QueryCondition(persona=Persona(name='Software Engineer', role_description='Focuses on coding best practices and system design.'), term='microservices', query_style='Formal', query_length='Medium', context='Microservices are an architectural style where applications are structured as a collection of loosely coupled services. Each service is fine-grained and focuses on a single functionality.'), GeneratedQueryAnswer(query='What is the purpose of microservices in software architecture?', answer='Microservices are designed to structure applications as a collection of loosely coupled services, each focusing on a single functionality.'))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english), property_name='entities'), 0.3333333333333333), (MultiHopAbstractQuerySynthesizer(name='multi_hop_abstract_query_synthesizer', llm=LangchainLLMWrapper(langchain_llm=ChatOllama(...)), generate_query_reference_prompt=QueryAnswerGenerationPrompt(instruction=Generate a multi-hop query and answer based on the specified conditions (persona, themes, style, length) and the provided context. The themes represent a set of phrases either extracted or generated from the context, which highlight the suitability of the selected context for multi-hop query creation. Ensure the query explicitly incorporates these themes.### Instructions:\n",
      "1. **Generate a Multi-Hop Query**: Use the provided context segments and themes to form a query that requires combining information from multiple segments (e.g., `<1-hop>` and `<2-hop>`). Ensure the query explicitly incorporates one or more themes and reflects their relevance to the context.\n",
      "2. **Generate an Answer**: Use only the content from the provided context to create a detailed and faithful answer to the query. Avoid adding information that is not directly present or inferable from the given context.\n",
      "3. **Multi-Hop Context Tags**:\n",
      "   - Each context segment is tagged as `<1-hop>`, `<2-hop>`, etc.\n",
      "   - Ensure the query uses information from at least two segments and connects them meaningfully., examples=[(QueryConditions(persona=Persona(name='Historian', role_description='Focuses on major scientific milestones and their global impact.'), themes=['Theory of Relativity', 'Experimental Validation'], query_style='Formal', query_length='Medium', context=['<1-hop> Albert Einstein developed the theory of relativity, introducing the concept of spacetime.', '<2-hop> The bending of light by gravity was confirmed during the 1919 solar eclipse, supporting Einstein’s theory.']), GeneratedQueryAnswer(query='How was the experimental validation of the theory of relativity achieved during the 1919 solar eclipse?', answer='The experimental validation of the theory of relativity was achieved during the 1919 solar eclipse by confirming the bending of light by gravity, which supported Einstein’s concept of spacetime as proposed in the theory.'))], language=english), concept_combination_prompt=ConceptCombinationPrompt(instruction=Form combinations by pairing concepts from at least two different lists.\n",
      "**Instructions:**\n",
      "- Review the concepts from each node.\n",
      "- Identify concepts that can logically be connected or contrasted.\n",
      "- Form combinations that involve concepts from different nodes.\n",
      "- Each combination should include at least one concept from two or more nodes.\n",
      "- List the combinations clearly and concisely.\n",
      "- Do not repeat the same combination more than once., examples=[(ConceptsList(lists_of_concepts=[['Artificial intelligence', 'Automation'], ['Healthcare', 'Data privacy']], max_combinations=2), ConceptCombinations(combinations=[['Artificial intelligence', 'Healthcare'], ['Automation', 'Data privacy']]))], language=english), theme_persona_matching_prompt=ThemesPersonasMatchingPrompt(instruction=Given a list of themes and personas with their roles, associate each persona with relevant themes based on their role description., examples=[(ThemesPersonasInput(themes=['Empathy', 'Inclusivity', 'Remote work'], personas=[Persona(name='HR Manager', role_description='Focuses on inclusivity and employee support.'), Persona(name='Remote Team Lead', role_description='Manages remote team communication.')]), PersonaThemesMapping(mapping={'HR Manager': ['Inclusivity', 'Empathy'], 'Remote Team Lead': ['Remote work', 'Empathy']}))], language=english)), 0.3333333333333333)]\n"
     ]
    }
   ],
   "source": [
    "loaded_kg = KnowledgeGraph.load(\"knowledge_graph.json\")\n",
    "print(\"KnowledgeGraph cargado:\", loaded_kg)  # Debería mostrar el número actualizado de nodos y relaciones\n",
    "\n",
    "# 6. Crear el TestsetGenerator usando el KnowledgeGraph enriquecido\n",
    "from ragas.testset import TestsetGenerator\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "generator = TestsetGenerator(\n",
    "    llm=generator_llm,\n",
    "    embedding_model=embedding_model,\n",
    "    knowledge_graph=loaded_kg\n",
    ")\n",
    "\n",
    "# 7. Definir la distribución de queries a generar (usando la distribución por defecto)\n",
    "from ragas.testset.synthesizers import default_query_distribution\n",
    "\n",
    "query_distribution = default_query_distribution(generator_llm)\n",
    "print(\"Distribución original de queries:\", query_distribution)\n",
    "\n",
    "# Filtrar la distribución para eliminar el sintetizador multi_hop_specific_query_synthesizer\n",
    "filtered_query_distribution = [\n",
    "    (synth, prob) for synth, prob in query_distribution \n",
    "    if synth.name != \"multi_hop_specific_query_synthesizer\"\n",
    "]\n",
    "\n",
    "print(\"Distribución filtrada de queries:\", filtered_query_distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1ac8c01-e423-4599-a42a-4ea0dd288ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating personas: 100%|███████████████████████████████████████████████████████████████| 3/3 [00:01<00:00,  1.77it/s]\n",
      "Generating Scenarios: 100%|█████████████████████████████████████████████████████████████| 2/2 [09:34<00:00, 287.11s/it]\n",
      "Generating Samples: 100%|████████████████████████████████████████████████████████████████| 8/8 [00:17<00:00,  2.18s/it]\n"
     ]
    }
   ],
   "source": [
    "# Generar el testset usando la distribución filtrada\n",
    "testset = generator.generate(testset_size=10, query_distribution=filtered_query_distribution)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6cd91c8b-a7b2-4d79-a25c-a0a2c1aad6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          user_input  \\\n",
      "0         what does ACTION mean in JC3IEDM overview?   \n",
      "1   What is the role of ACTION in the JC3IEDM model?   \n",
      "2  What is the capability referred to in military...   \n",
      "3  What does CAPABILITY refer to in the context o...   \n",
      "4  What are some examples of independent entities...   \n",
      "5  What are the dynamics involved in identifying ...   \n",
      "6  What are some independent entities that can be...   \n",
      "7  What dynamics govern the relationships between...   \n",
      "\n",
      "                                  reference_contexts  \\\n",
      "0  [JC3IEDM OVERVIEW – UK – DMWG 16 February 2007...   \n",
      "1  [JC3IEDM OVERVIEW – UK – DMWG 16 February 2007...   \n",
      "2  [Dynamics (How, what, when something is to be ...   \n",
      "3  [Dynamics (How, what, when something is to be ...   \n",
      "4  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
      "5  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
      "6  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
      "7  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
      "\n",
      "                                           reference  \\\n",
      "0  ACTION refers to an activity, or the occurrenc...   \n",
      "1  ACTION is an activity, or the occurrence of an...   \n",
      "2  The capability refers to the potential ability...   \n",
      "3  CAPABILITY refers to the potential ability to ...   \n",
      "4  Independent entities, as defined in Table 9, i...   \n",
      "5  The dynamics involved in identifying independe...   \n",
      "6  Independent entities that can be used as candi...   \n",
      "7  The dynamics that govern the relationships bet...   \n",
      "\n",
      "                       synthesizer_name  \n",
      "0  single_hop_specifc_query_synthesizer  \n",
      "1  single_hop_specifc_query_synthesizer  \n",
      "2  single_hop_specifc_query_synthesizer  \n",
      "3  single_hop_specifc_query_synthesizer  \n",
      "4  multi_hop_abstract_query_synthesizer  \n",
      "5  multi_hop_abstract_query_synthesizer  \n",
      "6  multi_hop_abstract_query_synthesizer  \n",
      "7  multi_hop_abstract_query_synthesizer  \n"
     ]
    }
   ],
   "source": [
    "# Convertir a DataFrame para visualizar resultados\n",
    "df = testset.to_pandas()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9d3e9b4-39fb-43b7-b663-78777810957f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_input</th>\n",
       "      <th>reference_contexts</th>\n",
       "      <th>reference</th>\n",
       "      <th>synthesizer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what does ACTION mean in JC3IEDM overview?</td>\n",
       "      <td>[JC3IEDM OVERVIEW – UK – DMWG 16 February 2007...</td>\n",
       "      <td>ACTION refers to an activity, or the occurrenc...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What is the role of ACTION in the JC3IEDM model?</td>\n",
       "      <td>[JC3IEDM OVERVIEW – UK – DMWG 16 February 2007...</td>\n",
       "      <td>ACTION is an activity, or the occurrence of an...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What is the capability referred to in military...</td>\n",
       "      <td>[Dynamics (How, what, when something is to be ...</td>\n",
       "      <td>The capability refers to the potential ability...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What does CAPABILITY refer to in the context o...</td>\n",
       "      <td>[Dynamics (How, what, when something is to be ...</td>\n",
       "      <td>CAPABILITY refers to the potential ability to ...</td>\n",
       "      <td>single_hop_specifc_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What are some examples of independent entities...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...</td>\n",
       "      <td>Independent entities, as defined in Table 9, i...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>What are the dynamics involved in identifying ...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...</td>\n",
       "      <td>The dynamics involved in identifying independe...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What are some independent entities that can be...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...</td>\n",
       "      <td>Independent entities that can be used as candi...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What dynamics govern the relationships between...</td>\n",
       "      <td>[&lt;1-hop&gt;\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...</td>\n",
       "      <td>The dynamics that govern the relationships bet...</td>\n",
       "      <td>multi_hop_abstract_query_synthesizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          user_input  \\\n",
       "0         what does ACTION mean in JC3IEDM overview?   \n",
       "1   What is the role of ACTION in the JC3IEDM model?   \n",
       "2  What is the capability referred to in military...   \n",
       "3  What does CAPABILITY refer to in the context o...   \n",
       "4  What are some examples of independent entities...   \n",
       "5  What are the dynamics involved in identifying ...   \n",
       "6  What are some independent entities that can be...   \n",
       "7  What dynamics govern the relationships between...   \n",
       "\n",
       "                                  reference_contexts  \\\n",
       "0  [JC3IEDM OVERVIEW – UK – DMWG 16 February 2007...   \n",
       "1  [JC3IEDM OVERVIEW – UK – DMWG 16 February 2007...   \n",
       "2  [Dynamics (How, what, when something is to be ...   \n",
       "3  [Dynamics (How, what, when something is to be ...   \n",
       "4  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
       "5  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
       "6  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
       "7  [<1-hop>\\n\\nJC3IEDM OVERVIEW – UK – DMWG 16 Fe...   \n",
       "\n",
       "                                           reference  \\\n",
       "0  ACTION refers to an activity, or the occurrenc...   \n",
       "1  ACTION is an activity, or the occurrence of an...   \n",
       "2  The capability refers to the potential ability...   \n",
       "3  CAPABILITY refers to the potential ability to ...   \n",
       "4  Independent entities, as defined in Table 9, i...   \n",
       "5  The dynamics involved in identifying independe...   \n",
       "6  Independent entities that can be used as candi...   \n",
       "7  The dynamics that govern the relationships bet...   \n",
       "\n",
       "                       synthesizer_name  \n",
       "0  single_hop_specifc_query_synthesizer  \n",
       "1  single_hop_specifc_query_synthesizer  \n",
       "2  single_hop_specifc_query_synthesizer  \n",
       "3  single_hop_specifc_query_synthesizer  \n",
       "4  multi_hop_abstract_query_synthesizer  \n",
       "5  multi_hop_abstract_query_synthesizer  \n",
       "6  multi_hop_abstract_query_synthesizer  \n",
       "7  multi_hop_abstract_query_synthesizer  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b4208cf-5c16-4d2b-84b6-548d3b962494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testset uploaded! View at https://app.ragas.io/dashboard/alignment/testset/1bd690a2-e994-4c43-86a3-e182eca45bd7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://app.ragas.io/dashboard/alignment/testset/1bd690a2-e994-4c43-86a3-e182eca45bd7'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ[\"RAGAS_APP_TOKEN\"] = \"apt.4054-53fd2731274f-4395-87c1-2cd16721-ebca3\"\n",
    "testset.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d4dd75-52e8-4310-b049-cc5c76eb7bcf",
   "metadata": {},
   "source": [
    "En la salida aparecen 4 columnas:\n",
    "- user input que hace referencia a la pregunta introducida por el usuario\n",
    "- reference_context son el conjunto de fragmentos o extractos de texto que se han recuperado del documento y que sustentan o justifica la respuesta\n",
    "- reference es la respuesta \"ideal\" o esperada. El ground truth \n",
    "- synthesizer_name. Es el nombre del sintetizador que se uso para crear la muestra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1ef981-6344-482e-a431-45685927d86b",
   "metadata": {},
   "source": [
    "### Evaluación del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5cb21930-94e0-485a-ba43-7840fe4351ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['user_input', 'reference_contexts', 'reference', 'synthesizer_name'],\n",
       "    num_rows: 8\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = Dataset.from_dict(df)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b292b9e-daf5-4843-b964-492311c1b4ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['user_input', 'retrieved_contexts', 'response', 'reference'],\n",
      "    num_rows: 8\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "# Supongamos que 'df' es el DataFrame obtenido del testset, por ejemplo:\n",
    "# df = testset.to_pandas()\n",
    "\n",
    "result_list = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    user_input = row[\"user_input\"]\n",
    "    reference = row[\"reference\"]\n",
    "    \n",
    "    # Recuperar los documentos relevantes a partir de la consulta del usuario\n",
    "    relevant_docs = rag.get_most_relevant_docs(user_input)\n",
    "    # Generar la respuesta usando los documentos relevantes\n",
    "    response = rag.generate_answer(user_input, relevant_docs)\n",
    "    \n",
    "    # Extraer el contenido de los documentos relevantes\n",
    "    retrieved_contexts = [doc.page_content for doc in relevant_docs]\n",
    "    \n",
    "    sample = {\n",
    "        \"user_input\": user_input,\n",
    "        \"retrieved_contexts\": retrieved_contexts,\n",
    "        \"response\": response,\n",
    "        \"reference\": reference\n",
    "    }\n",
    "    \n",
    "    result_list.append(sample)\n",
    "\n",
    "# Convertir la lista de diccionarios en un Dataset de Hugging Face\n",
    "dataset = Dataset.from_dict({\n",
    "    \"user_input\": [sample[\"user_input\"] for sample in result_list],\n",
    "    \"retrieved_contexts\": [sample[\"retrieved_contexts\"] for sample in result_list],\n",
    "    \"response\": [sample[\"response\"] for sample in result_list],\n",
    "    \"reference\": [sample[\"reference\"] for sample in result_list]\n",
    "})\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9029de7d-2bf3-40cf-b97b-62b753c37422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función que genera la referencia utilizando el LLM generador.\n",
    "# Aquí se puede reutilizar la misma función que usas para 'generate_answer' o definir otra si la lógica debe ser distinta.\n",
    "def generate_reference(query, relevant_docs):\n",
    "    # Por ejemplo, se podría llamar al mismo método:\n",
    "    return rag.generate_answer(query, relevant_docs)\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for query in questions:\n",
    "    # Recuperar documentos relevantes para la consulta\n",
    "    relevant_docs = rag.get_most_relevant_docs(query)\n",
    "    # Generar la respuesta (lo que el sistema haría en modo producción)\n",
    "    response = rag.generate_answer(query, relevant_docs)\n",
    "    # Generar la referencia usando el LLM generador (esta será la \"ground truth\" para la evaluación)\n",
    "    reference = generate_reference(query, relevant_docs)\n",
    "    \n",
    "    sample = {\n",
    "        \"user_input\": query,\n",
    "        \"retrieved_contexts\": [doc.page_content for doc in relevant_docs],\n",
    "        \"response\": response,\n",
    "        \"reference\": reference\n",
    "    }\n",
    "    dataset.append(sample)\n",
    "\n",
    "# Si prefieres trabajar con un EvaluationDataset de ragas:\n",
    "from ragas import EvaluationDataset\n",
    "\n",
    "evaluation_dataset = EvaluationDataset.from_list(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd8cf8c2-ab0f-4b7a-b3d8-53f37b159e5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|████████████████████████████████████████████████████████████████████████| 9/9 [00:46<00:00,  5.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'context_recall': 1.0000, 'faithfulness': 1.0000, 'factual_correctness(mode=f1)': 0.8233}\n"
     ]
    }
   ],
   "source": [
    "from ragas import evaluate\n",
    "from ragas.llms import LangchainLLMWrapper\n",
    "from ragas.metrics import LLMContextRecall, Faithfulness, FactualCorrectness\n",
    "\n",
    "# Configurar el evaluador LLM y embeddings si es necesario\n",
    "evaluator_llm = LangchainLLMWrapper(ChatOllama(model=\"llama3\", base_url=\"https://ollama.gsi.upm.es/\"))\n",
    "# evaluator_embeddings si se requiere, de forma similar\n",
    "\n",
    "result = evaluate(\n",
    "    dataset=evaluation_dataset,\n",
    "    metrics=[LLMContextRecall(), Faithfulness(), FactualCorrectness()],\n",
    "    llm=evaluator_llm\n",
    ")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae609f71-c582-43de-a5c9-8ece535c00da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f418be3-c11b-494f-9935-984289e4bee7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
